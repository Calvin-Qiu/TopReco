#!/usr/bin/env python 
import os

import tensorflow as tf
import numpy as np
import sklearn.metrics

import matplotlib.pyplot as plt

from root_gnn.src.datasets import graph
from root_gnn.src.datasets import herwig_hadrons as hhdata
from root_gnn.src.models import model_utils

from root_gnn import utils_plot

ckpt_name = 'checkpoint'

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description='Calculate the metrics for jet reco.')
    add_arg = parser.add_argument
    add_arg("filenames", help="input event files in TFRec format")
    add_arg("config", help="configuration file used for training")
    add_arg("outname", help='output name prefix')
    add_arg("--nevts", default=-1, help='number of events', type=int)
    args = parser.parse_args()

    outname = args.outname

    if not os.path.exists(args.config):
        print("{} does not exists", args.config)


    # load data
    filenames = tf.io.gfile.glob(args.filenames)
    AUTO = tf.data.experimental.AUTOTUNE
    dataset = tf.data.TFRecordDataset(filenames)
    dataset = dataset.map(graph.parse_tfrec_function, num_parallel_calls=AUTO)
    nevts = sum([1 for _ in dataset])
    print("{} files and {:,} events".format(len(filenames), nevts))
    print("maximum {} nodes in one graph".format(hhdata.max_nodes)) 

    model, _, _ = model_utils.create_load_model(args.config)
    num_processing_steps = hhdata.max_nodes

    node_preds = [] # node prediction
    node_props = [] # node properties
    truth_node_pred = []
    truth_node_prop = []
    root_props = []

    ievt = 0  
    for event in dataset:
        if args.nevts > 0 and ievt >= args.nevts:
            break

        inputs, targets = event
        node_pred, global_pred = model(inputs, num_processing_steps)
        global_pred = tf.squeeze(tf.concat(global_pred, axis=-1))

        node_preds.append(global_pred)
        node_props.append(node_pred)
        root_props.append(inputs.nodes)
        truth_node_pred.append(tf.squeeze(targets.globals).numpy())
        truth_node_prop.append(tf.concat([targets.nodes[1:, :],\
            tf.zeros([1, targets.nodes.shape[1]])], axis=0).numpy())
        ievt += 1

    res_nps = {}
    res_nps["root_node_props"] = np.concatenate(root_props, axis=0)
    # the evaluation is performed for each step, in which a global score indicates
    # if a new node to be added. The higher the value is the more likely the node is added.
    # And in the mean time, predict the four-momentum of the new nodes.
    for istep in range(num_processing_steps):
        inode_preds = np.array([x[istep] for x in node_preds])
        truth_inode_pred = np.array([x[istep] for x in truth_node_pred])

        res_nps['node_preds_{}'.format(istep)] = inode_preds
        res_nps['node_preds_{}_truth'.format(istep)] = inode_preds

        for iprop in range(4):
            inode_props = np.array([x[istep][iprop] for x in node_props])
            inode_props_truth = np.array([x[istep][iprop] for x in truth_node_prop])

            res_nps['node_props_{}_{}'.format(istep, iprop)] = inode_props
            res_nps['node_props_{}_{}_truth'.format(istep, iprop)] = inode_props_truth

    np.savez(args.outname+".npz", **res_nps)