#!/usr/bin/env python
import ROOT
import os

import tensorflow as tf
import numpy as np
import sklearn.metrics

from graph_nets import utils_tf
import sonnet as snt

from root_gnn.src.datasets import wprime
from root_gnn import model as GNN
from root_gnn.utils import load_yaml

ckpt_name = 'checkpoint'
if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description='Calculate the metrics for jet reco.')
    add_arg = parser.add_argument
    add_arg("filename", help="input event files")
    add_arg("config", help="configuration file used for training")
    add_arg("outname", help='output name prefix')
    add_arg("--nevts", default=-1, help='number of events', type=int)
    add_arg("--skip-nevts", default=0, help='skip number of events', type=int)
    add_arg("--modeldir", help="Overwrite the model directory from the configuration file", default=None)
    add_arg("--edge-threshold", help='threshold on edge scores', type=float, default=0.5)
    add_arg("--node-threshold", help='threshold on node scores', type=float, default=0.5)

    args = parser.parse_args()


    if not os.path.exists(args.filename):
        print("{} does not exists", args.filename)


    # config ML model
    config = load_yaml(args.config)

    prod_name = config['prod_name']
    modeldir = os.path.join(config['output_dir'], prod_name)
    if args.modeldir is not None:
        modeldir = args.modeldir
    
    config_tr = config['parameters']
    global_batch_size = config_tr['batch_size']
    num_processing_steps_tr = config_tr['n_iters']      ## level of message-passing
    learning_rate = config_tr['learning_rate']

    optimizer = snt.optimizers.Adam(learning_rate)
    model = getattr(GNN, config['model_name'])()
    checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)
    ckpt_manager = tf.train.CheckpointManager(checkpoint, directory=modeldir, max_to_keep=5)
    if os.path.exists(os.path.join(modeldir, ckpt_name)):
        status = checkpoint.restore(ckpt_manager.latest_checkpoint).expect_partial()
        print("Loaded latest checkpoint from {}".format(modeldir))
    else:
        raise ValueError("Cannot find model at:", modeldir)


    iskip = 0
    ievt = 0
    evt_info = []
    node_predicts = []
    edge_predicts = []
    node_truths = []
    edge_truths = []
    edge_threshold = args.edge_threshold
    node_threshold = args.node_threshold


    n_gnn_particles = []
    n_ljet_particles = []
    n_gnn_ljet_particles = []
    n_gnn_only_particles = []
    n_ljet_only_particles = []

    for event in wprime.read(args.filename):
        if iskip < args.skip_nevts:
            iskip += 1
            continue
        if args.nevts > 0 and ievt >= args.nevts:
            break
        
        ievt += 1
        inputs_tr, targets_tr = wprime.make_graph(event)[0]
        outputs_tr = model(inputs_tr, num_processing_steps_tr)
        output_graph = outputs_tr[-1]
        node_predicts.append(output_graph.nodes.numpy())
        node_truths.append(targets_tr.nodes.numpy())
        edge_predicts.append(output_graph.edges.numpy())
        edge_truths.append(targets_tr.edges.numpy())

        # calculate similar variables for GNN-based reconstruction
        # method-one, place a threshold on edge score
        edge_predict = np.squeeze(output_graph.edges.numpy())
        edge_passed = edge_predict > edge_threshold
        nodes_sel = np.unique(np.concatenate([output_graph.receivers.numpy()[edge_passed],\
            output_graph.senders.numpy()[edge_passed]], axis=0))
        gnn_tlv = wprime.invariant_mass(event, nodes_sel.tolist())
        # print("selected particles: ", nodes_sel)

        # obtain GNN-based reconstruction using node score only
        node_predict = np.squeeze(output_graph.nodes.numpy())
        if len(node_predict.shape) == 1:
            # print("reconstruction using node information.")
            node_passed = node_predict > node_threshold
            nodes_sel_from_nodes = np.arange(output_graph.nodes.shape[0])[node_passed]
            gnn_tlv_node_only = wprime.invariant_mass(event, nodes_sel_from_nodes.tolist())
        else:
            gnn_tlv_node_only = wprime.ZERO

        ljet, wboson = wprime.evaluate_evt(event)
        # print(wboson.E(), gnn_tlv.E())
        evt_info.append([ljet.E(), ljet.Eta(), ljet.Phi(), ljet.M(),
                wboson.E(), wboson.Eta(), wboson.Phi(), wboson.M(),
                gnn_tlv.E(), gnn_tlv.Eta(), gnn_tlv.Phi(), gnn_tlv.M(),
                gnn_tlv_node_only.E(), gnn_tlv_node_only.Eta(), gnn_tlv_node_only.Phi(), gnn_tlv_node_only.M()
                ])
        # check further the particles selected by GNN and those by leading jet
        gnnset = set(nodes_sel.tolist())
        ljetset = set(wprime.ljet_particles(event))
        n_gnn_particles.append(len(gnnset))
        n_ljet_particles.append(len(ljetset))
        n_gnn_ljet_particles.append(len(gnnset.intersection(ljetset)))
        n_gnn_only_particles.append(len(gnnset.difference(ljetset)))
        n_ljet_only_particles.append(len(ljetset.difference(gnnset)))


    node_predicts = np.concatenate(node_predicts, axis=0)
    node_truths = np.concatenate(node_truths, axis=0)
    edge_predicts = np.concatenate(edge_predicts, axis=0)
    edge_truths = np.concatenate(edge_truths, axis=0)
    evt_info = np.array(evt_info, dtype=np.float32)
    n_gnn_particles = np.array(n_gnn_particles)
    n_ljet_particles = np.array(n_ljet_particles)
    n_gnn_ljet_particles = np.array(n_gnn_ljet_particles)
    n_gnn_only_particles = np.array(n_gnn_only_particles)
    n_ljet_only_particles = np.array(n_ljet_only_particles)

    np.savez(args.outname+".npz",\
        node_predicts=node_predicts,
        node_truths=node_truths,
        edge_predicts=edge_predicts,
        edge_truths=edge_truths,
        evt_info=evt_info,
        n_gnn_particles=n_gnn_particles,
        n_ljet_particles=n_ljet_particles,
        n_gnn_ljet_particles=n_gnn_ljet_particles,
        n_gnn_only_particles=n_gnn_only_particles,
        n_ljet_only_particles=n_ljet_only_particles
    )